{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison for Object Detection\n",
    "\n",
    "This notebook compares different object detection models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "print('Libraries imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated model performance data\n",
    "models = ['YOLOv8', 'Faster R-CNN', 'SSD', 'EfficientDet', 'RetinaNet']\n",
    "\n",
    "performance_data = {\n",
    "    'YOLOv8': {'mAP': 0.85, 'FPS': 45, 'params': 11.2, 'size': 42},\n",
    "    'Faster R-CNN': {'mAP': 0.88, 'FPS': 7, 'params': 41.5, 'size': 165},\n",
    "    'SSD': {'mAP': 0.79, 'FPS': 30, 'params': 24.3, 'size': 95},\n",
    "    'EfficientDet': {'mAP': 0.87, 'FPS': 25, 'params': 6.6, 'size': 25},\n",
    "    'RetinaNet': {'mAP': 0.86, 'FPS': 15, 'params': 36.4, 'size': 145}\n",
    "}\n",
    "\n",
    "df_models = pd.DataFrame.from_dict(performance_data, orient='index')\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(df_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# mAP comparison\n",
    "axes[0, 0].bar(df_models.index, df_models['mAP'], color='skyblue')\n",
    "axes[0, 0].set_ylabel('mAP')\n",
    "axes[0, 0].set_title('Mean Average Precision (higher is better)')\n",
    "axes[0, 0].set_ylim(0.75, 0.9)\n",
    "\n",
    "# FPS comparison\n",
    "axes[0, 1].bar(df_models.index, df_models['FPS'], color='lightgreen')\n",
    "axes[0, 1].set_ylabel('FPS')\n",
    "axes[0, 1].set_title('Frames Per Second (higher is better)')\n",
    "\n",
    "# Model size comparison\n",
    "axes[1, 0].bar(df_models.index, df_models['size'], color='coral')\n",
    "axes[1, 0].set_ylabel('Size (MB)')\n",
    "axes[1, 0].set_title('Model Size (lower is better)')\n",
    "\n",
    "# mAP vs Speed scatter\n",
    "axes[1, 1].scatter(df_models['FPS'], df_models['mAP'], s=df_models['size']*5, alpha=0.6)\n",
    "for idx, model in enumerate(df_models.index):\n",
    "    axes[1, 1].annotate(model, (df_models['FPS'].iloc[idx], df_models['mAP'].iloc[idx]))\n",
    "axes[1, 1].set_xlabel('FPS')\n",
    "axes[1, 1].set_ylabel('mAP')\n",
    "axes[1, 1].set_title('Speed vs Accuracy Trade-off')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark inference speed\n",
    "def benchmark_inference(model_name, num_iterations=100):\n",
    "    \"\"\"Simulate inference benchmarking\"\"\"\n",
    "    # Simulated inference times\n",
    "    base_times = {\n",
    "        'YOLOv8': 22,\n",
    "        'Faster R-CNN': 143,\n",
    "        'SSD': 33,\n",
    "        'EfficientDet': 40,\n",
    "        'RetinaNet': 67\n",
    "    }\n",
    "    \n",
    "    base_time = base_times.get(model_name, 50)\n",
    "    times = np.random.normal(base_time, base_time * 0.1, num_iterations)\n",
    "    \n",
    "    return {\n",
    "        'mean': np.mean(times),\n",
    "        'std': np.std(times),\n",
    "        'min': np.min(times),\n",
    "        'max': np.max(times),\n",
    "        'median': np.median(times)\n",
    "    }\n",
    "\n",
    "# Run benchmarks\n",
    "benchmark_results = {}\n",
    "for model in models:\n",
    "    benchmark_results[model] = benchmark_inference(model)\n",
    "\n",
    "df_benchmark = pd.DataFrame(benchmark_results).T\n",
    "print(\"Inference Time Benchmark (ms):\")\n",
    "print(df_benchmark.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection recommendations\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL SELECTION GUIDE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüéØ Best for Real-time Applications:\")\n",
    "print(\"  ‚Ä¢ YOLOv8: Best balance of speed and accuracy\")\n",
    "print(\"  ‚Ä¢ SSD: Good for resource-constrained environments\")\n",
    "\n",
    "print(\"\\nüî¨ Best for Accuracy:\")\n",
    "print(\"  ‚Ä¢ Faster R-CNN: Highest mAP, suitable for offline processing\")\n",
    "print(\"  ‚Ä¢ EfficientDet: Good accuracy with smaller model size\")\n",
    "\n",
    "print(\"\\nüì± Best for Mobile/Edge Devices:\")\n",
    "print(\"  ‚Ä¢ EfficientDet: Smallest model size with good accuracy\")\n",
    "print(\"  ‚Ä¢ YOLOv8: Can be optimized for mobile deployment\")\n",
    "\n",
    "print(\"\\n‚öñÔ∏è Balanced Choice:\")\n",
    "print(\"  ‚Ä¢ EfficientDet: Good trade-off between all metrics\")\n",
    "print(\"  ‚Ä¢ RetinaNet: Solid performance across the board\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
