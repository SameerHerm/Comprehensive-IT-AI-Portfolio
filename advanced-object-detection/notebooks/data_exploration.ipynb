{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration for Object Detection\n",
    "\n",
    "This notebook explores the dataset for object detection model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print('Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = Path('../data')\n",
    "ANNOTATIONS_DIR = DATA_DIR / 'annotations'\n",
    "IMAGES_DIR = DATA_DIR / 'raw'\n",
    "\n",
    "# Check directories\n",
    "print(f\"Data directory exists: {DATA_DIR.exists()}\")\n",
    "print(f\"Annotations directory exists: {ANNOTATIONS_DIR.exists()}\")\n",
    "print(f\"Images directory exists: {IMAGES_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COCO-style annotations\n",
    "def load_coco_annotations(annotation_file):\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        annotations = json.load(f)\n",
    "    return annotations\n",
    "\n",
    "# Example loading\n",
    "# annotations = load_coco_annotations(ANNOTATIONS_DIR / 'train.json')\n",
    "# print(f\"Loaded {len(annotations['images'])} images\")\n",
    "# print(f\"Loaded {len(annotations['annotations'])} annotations\")\n",
    "# print(f\"Number of categories: {len(annotations['categories'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample dataset statistics\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate dataset\n",
    "num_images = 1000\n",
    "num_classes = 20\n",
    "class_names = [f'class_{i}' for i in range(num_classes)]\n",
    "\n",
    "# Generate random annotations\n",
    "annotations_data = []\n",
    "for img_id in range(num_images):\n",
    "    num_objects = np.random.randint(1, 10)\n",
    "    for _ in range(num_objects):\n",
    "        annotations_data.append({\n",
    "            'image_id': img_id,\n",
    "            'category_id': np.random.randint(0, num_classes),\n",
    "            'bbox': [np.random.rand() * 100, np.random.rand() * 100, \n",
    "                    np.random.rand() * 200, np.random.rand() * 200],\n",
    "            'area': np.random.rand() * 10000\n",
    "        })\n",
    "\n",
    "df_annotations = pd.DataFrame(annotations_data)\n",
    "print(f\"Total annotations: {len(df_annotations)}\")\n",
    "print(f\"Average objects per image: {len(df_annotations) / num_images:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "class_counts = df_annotations['category_id'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(len(class_counts)), class_counts.values)\n",
    "plt.xlabel('Class ID')\n",
    "plt.ylabel('Number of Instances')\n",
    "plt.title('Class Distribution')\n",
    "plt.xticks(range(0, num_classes, 2))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(class_counts.values[:10], labels=[f'Class {i}' for i in range(10)], autopct='%1.1f%%')\n",
    "plt.title('Top 10 Classes Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounding box size analysis\n",
    "df_annotations['width'] = df_annotations['bbox'].apply(lambda x: x[2])\n",
    "df_annotations['height'] = df_annotations['bbox'].apply(lambda x: x[3])\n",
    "df_annotations['aspect_ratio'] = df_annotations['width'] / (df_annotations['height'] + 1e-6)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].hist(df_annotations['width'], bins=50, edgecolor='black')\n",
    "axes[0].set_xlabel('Width (pixels)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Bounding Box Width Distribution')\n",
    "\n",
    "axes[1].hist(df_annotations['height'], bins=50, edgecolor='black')\n",
    "axes[1].set_xlabel('Height (pixels)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Bounding Box Height Distribution')\n",
    "\n",
    "axes[2].hist(df_annotations['aspect_ratio'], bins=50, edgecolor='black')\n",
    "axes[2].set_xlabel('Aspect Ratio (W/H)')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].set_title('Aspect Ratio Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze image properties\n",
    "def analyze_images(image_dir, num_samples=100):\n",
    "    image_stats = []\n",
    "    \n",
    "    # Generate sample image stats\n",
    "    for i in range(num_samples):\n",
    "        # Simulate image properties\n",
    "        width = np.random.choice([640, 1280, 1920])\n",
    "        height = np.random.choice([480, 720, 1080])\n",
    "        channels = 3\n",
    "        \n",
    "        image_stats.append({\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'channels': channels,\n",
    "            'aspect_ratio': width / height,\n",
    "            'total_pixels': width * height\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(image_stats)\n",
    "\n",
    "df_images = analyze_images(IMAGES_DIR)\n",
    "print(\"Image Statistics:\")\n",
    "print(df_images.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image resolution distribution\n",
    "resolution_counts = df_images.groupby(['width', 'height']).size().reset_index(name='count')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for _, row in resolution_counts.iterrows():\n",
    "    plt.scatter(row['width'], row['height'], s=row['count']*50, alpha=0.6)\n",
    "    plt.text(row['width'], row['height'], f\"{row['width']}x{row['height']}\", \n",
    "             fontsize=9, ha='center')\n",
    "\n",
    "plt.xlabel('Width (pixels)')\n",
    "plt.ylabel('Height (pixels)')\n",
    "plt.title('Image Resolution Distribution')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for data quality issues\n",
    "def check_data_quality(df_annotations):\n",
    "    issues = []\n",
    "    \n",
    "    # Check for negative coordinates\n",
    "    negative_coords = df_annotations[\n",
    "        df_annotations['bbox'].apply(lambda x: any(coord < 0 for coord in x[:2]))\n",
    "    ]\n",
    "    if len(negative_coords) > 0:\n",
    "        issues.append(f\"Found {len(negative_coords)} annotations with negative coordinates\")\n",
    "    \n",
    "    # Check for zero area boxes\n",
    "    zero_area = df_annotations[df_annotations['area'] <= 0]\n",
    "    if len(zero_area) > 0:\n",
    "        issues.append(f\"Found {len(zero_area)} annotations with zero or negative area\")\n",
    "    \n",
    "    # Check for very small boxes\n",
    "    small_boxes = df_annotations[df_annotations['area'] < 100]\n",
    "    if len(small_boxes) > 0:\n",
    "        issues.append(f\"Found {len(small_boxes)} very small boxes (area < 100 pixels)\")\n",
    "    \n",
    "    # Check for extreme aspect ratios\n",
    "    extreme_ar = df_annotations[\n",
    "        (df_annotations['aspect_ratio'] < 0.1) | (df_annotations['aspect_ratio'] > 10)\n",
    "    ]\n",
    "    if len(extreme_ar) > 0:\n",
    "        issues.append(f\"Found {len(extreme_ar)} boxes with extreme aspect ratios\")\n",
    "    \n",
    "    return issues\n",
    "\n",
    "quality_issues = check_data_quality(df_annotations)\n",
    "if quality_issues:\n",
    "    print(\"‚ö†Ô∏è Data Quality Issues Found:\")\n",
    "    for issue in quality_issues:\n",
    "        print(f\"  - {issue}\")\n",
    "else:\n",
    "    print(\"‚úÖ No data quality issues found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample visualizations\n",
    "def create_sample_image_with_boxes(img_size=(640, 480), num_boxes=5):\n",
    "    \"\"\"Create a sample image with bounding boxes\"\"\"\n",
    "    # Create random image\n",
    "    img = np.random.randint(0, 255, (*img_size, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Add random boxes\n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, num_boxes))\n",
    "    \n",
    "    for i in range(num_boxes):\n",
    "        x1 = np.random.randint(0, img_size[0] - 100)\n",
    "        y1 = np.random.randint(0, img_size[1] - 100)\n",
    "        x2 = x1 + np.random.randint(50, 150)\n",
    "        y2 = y1 + np.random.randint(50, 150)\n",
    "        \n",
    "        color = tuple(int(c * 255) for c in colors[i][:3])\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(img, f'Object {i}', (x1, y1-5), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Display sample images\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(6):\n",
    "    sample_img = create_sample_image_with_boxes()\n",
    "    axes[i].imshow(sample_img)\n",
    "    axes[i].set_title(f'Sample {i+1}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Images with Annotations', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Split Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze train/val/test split\n",
    "split_ratios = {'train': 0.7, 'val': 0.15, 'test': 0.15}\n",
    "total_images = 1000\n",
    "\n",
    "split_counts = {split: int(total_images * ratio) \n",
    "                for split, ratio in split_ratios.items()}\n",
    "\n",
    "# Visualize split\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Pie chart\n",
    "ax1.pie(split_counts.values(), labels=split_counts.keys(), \n",
    "        autopct='%1.1f%%', startangle=90)\n",
    "ax1.set_title('Dataset Split Distribution')\n",
    "\n",
    "# Bar chart\n",
    "ax2.bar(split_counts.keys(), split_counts.values(), \n",
    "        color=['blue', 'orange', 'green'])\n",
    "ax2.set_ylabel('Number of Images')\n",
    "ax2.set_title('Dataset Split Counts')\n",
    "for i, (k, v) in enumerate(split_counts.items()):\n",
    "    ax2.text(i, v + 10, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Dataset Split:\")\n",
    "for split, count in split_counts.items():\n",
    "    print(f\"  {split}: {count} images ({split_ratios[split]*100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor Analysis for Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze optimal anchor boxes\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Get all box dimensions\n",
    "box_dims = df_annotations[['width', 'height']].values\n",
    "\n",
    "# Perform K-means clustering\n",
    "n_anchors = 9\n",
    "kmeans = KMeans(n_clusters=n_anchors, random_state=42)\n",
    "kmeans.fit(box_dims)\n",
    "\n",
    "# Get anchor boxes\n",
    "anchors = kmeans.cluster_centers_\n",
    "anchors = anchors[anchors[:, 0].argsort()]  # Sort by width\n",
    "\n",
    "# Visualize anchors\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(box_dims[:, 0], box_dims[:, 1], alpha=0.3, s=1)\n",
    "plt.scatter(anchors[:, 0], anchors[:, 1], c='red', s=100, marker='x', linewidths=3)\n",
    "plt.xlabel('Width')\n",
    "plt.ylabel('Height')\n",
    "plt.title('Anchor Boxes from K-means Clustering')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for i, (w, h) in enumerate(anchors):\n",
    "    rect = plt.Rectangle((0, i), w/10, h/10, \n",
    "                         linewidth=2, edgecolor='r', facecolor='none')\n",
    "    plt.gca().add_patch(rect)\n",
    "    plt.text(w/10 + 1, i + h/20, f'{w:.0f}x{h:.0f}', fontsize=8)\n",
    "\n",
    "plt.xlim(0, 50)\n",
    "plt.ylim(-1, n_anchors)\n",
    "plt.xlabel('Relative Width')\n",
    "plt.ylabel('Anchor Index')\n",
    "plt.title('Anchor Box Shapes')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Optimal Anchor Boxes:\")\n",
    "for i, (w, h) in enumerate(anchors):\n",
    "    print(f\"  Anchor {i+1}: {w:.1f} x {h:.1f} (aspect ratio: {w/h:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET EXPLORATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüìä Dataset Statistics:\")\n",
    "print(f\"  ‚Ä¢ Total images: {num_images}\")\n",
    "print(f\"  ‚Ä¢ Total annotations: {len(df_annotations)}\")\n",
    "print(f\"  ‚Ä¢ Number of classes: {num_classes}\")\n",
    "print(f\"  ‚Ä¢ Avg objects per image: {len(df_annotations)/num_images:.2f}\")\n",
    "\n",
    "print(\"\\nüìê Bounding Box Statistics:\")\n",
    "print(f\"  ‚Ä¢ Mean width: {df_annotations['width'].mean():.1f} pixels\")\n",
    "print(f\"  ‚Ä¢ Mean height: {df_annotations['height'].mean():.1f} pixels\")\n",
    "print(f\"  ‚Ä¢ Mean aspect ratio: {df_annotations['aspect_ratio'].mean():.2f}\")\n",
    "\n",
    "print(\"\\nüéØ Recommendations:\")\n",
    "print(\"  1. Consider data augmentation for underrepresented classes\")\n",
    "print(\"  2. Use the calculated anchor boxes for better detection\")\n",
    "print(\"  3. Apply image resizing to standard dimensions (640x640 or 1280x1280)\")\n",
    "print(\"  4. Implement class balancing strategies during training\")\n",
    "print(\"  5. Consider removing or fixing annotations with quality issues\")\n",
    "\n",
    "print(\"\\n‚úÖ Dataset is ready for model training!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
